{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbc552e-b98a-4233-b3de-4095f0d1a5b0",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation Notebook Explanation (Hinglish)\n",
    "\n",
    "Is notebook mein hum classification models ko evaluate karne ke liye k-fold cross-validation use karenge. Neeche har cell ka code aur uski theory + simple Hinglish explanation di gayi hai. Aap is markdown ko seedha Jupyter Notebook mein paste kar sakte hain.\n",
    "\n",
    "---\n",
    "## Cell 1: Libraries & Models Import\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "```\n",
    "- `LogisticRegression`, `SVC`, aur `RandomForestClassifier`: teen popular classification algorithms.\n",
    "- `numpy` (np) arrays aur numerical operations ke liye.\n",
    "- `load_digits`: sklearn ka built-in handwritten digits dataset.\n",
    "\n",
    "**Theory:** Logistic Regression ek linear model hai probability estimate ke liye; SVM (Support Vector Machine) hyperplane banata hai classes separate karne ke liye; Random Forest ensemble of decision trees hai, jisse overfitting kam hota hai. რ\n",
    "\n",
    "---\n",
    "## Cell 2: Load Dataset\n",
    "\n",
    "```python\n",
    "digits = load_digits()\n",
    "```\n",
    "- `load_digits()` se ek Bunch object milta hai jisme `.data` features aur `.target` labels hote hain.\n",
    "\n",
    "**Theory:** Digits dataset mein 8×8 pixel images of handwritten digits (0–9) hain; total ~1797 samples.\n",
    "\n",
    "---\n",
    "## Cell 3: Train/Test Split\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.3)\n",
    "```\n",
    "- `train_test_split`: dataset ko random split karta hai training aur testing subsets mein.\n",
    "- `test_size=0.3` matlab 30% data test ke liye.\n",
    "\n",
    "**Theory:** Hum model ko unseen data pe bhi evaluate karna chahte, isliye data split karke overfitting avoid kartے hain.\n",
    "\n",
    "---\n",
    "## Cell 4: Logistic Regression Evaluation\n",
    "\n",
    "```python\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "score_lr = lr.score(X_test, y_test)\n",
    "```\n",
    "- `fit()`: model ko training data pe train karta hai.\n",
    "- `score()`: test data pe accuracy calculate karta hai.\n",
    "\n",
    "**Theory:** Accuracy = (correct predictions)/(total predictions).\n",
    "\n",
    "---\n",
    "## Cell 5: SVM Evaluation\n",
    "\n",
    "```python\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "score_svm = svm.score(X_test, y_test)\n",
    "```\n",
    "- SVC ka default kernel `rbf` hota hai.\n",
    "- `score()` se accuracy milti hai.\n",
    "\n",
    "**Theory:** SVM data points ko boundary ke aas-paas support vectors ke through separate karta hai.\n",
    "\n",
    "---\n",
    "## Cell 6: Random Forest Evaluation\n",
    "\n",
    "```python\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "score_rf = rf.score(X_test, y_test)\n",
    "```\n",
    "- `RandomForestClassifier()`: default 100 trees.\n",
    "- `score()`: test set pe accuracy.\n",
    "\n",
    "**Theory:** Forest of trees ka average ya majority vote final prediction banata hai.\n",
    "\n",
    "---\n",
    "## Cell 7: Manual KFold Demo (Commented)\n",
    "\n",
    "```python\n",
    "# from sklearn.model_selection import KFold\n",
    "# kf = KFold(n_splits=3)\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "#     ...\n",
    "```\n",
    "- Commented code se manual KFold splitting dikhaya ja sakta tha.\n",
    "\n",
    "**Theory:** KFold splits data into `n_splits` parts; har fold ek baar test hota hai aur baaki training.\n",
    "\n",
    "---\n",
    "## Cell 8: Utility Function for Scoring\n",
    "\n",
    "```python\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "```\n",
    "- Reusable function jo training + scoring ek hi line mein karta hai.\n",
    "\n",
    "**Theory:** DRY principle (Don't Repeat Yourself) se code clean hota hai.\n",
    "\n",
    "---\n",
    "## Cell 9: Single Fold Score Check\n",
    "\n",
    "```python\n",
    "get_score(LogisticRegression(), X_train, X_test, y_train, y_test)\n",
    "```\n",
    "- Sirf ek train/test split ke upar Logistic Regression ki performance dekhna.\n",
    "\n",
    "---\n",
    "## Cell 10: Stratified K-Fold Cross-Validation\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "score_l = []\n",
    "score_svm = []\n",
    "score_rf = []\n",
    "for train_index, test_index in skf.split(digits.data, digits.target):\n",
    "    X_tr, X_te = digits.data[train_index], digits.data[test_index]\n",
    "    y_tr, y_te = digits.target[train_index], digits.target[test_index]\n",
    "    score_l.append(get_score(LogisticRegression(max_iter=1000), X_tr, X_te, y_tr, y_te))\n",
    "    score_svm.append(get_score(SVC(), X_tr, X_te, y_tr, y_te))\n",
    "    score_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_tr, X_te, y_tr, y_te))\n",
    "```\n",
    "- `StratifiedKFold`: ensures har fold mein class distribution same rahe.\n",
    "- Loop se har fold ke liye teen models ki accuracies calculate karte hain aur list mein append karte hain.\n",
    "\n",
    "**Theory:** Stratification se imbalance classes handle hoti hain; cross-validation se performance ka reliable estimate milta hai.\n",
    "\n",
    "---\n",
    "## Cell 11–13: Fold-wise Scores\n",
    "\n",
    "```python\n",
    "score_l    # Logistic scores for each fold\n",
    "score_svm  # SVM scores for each fold\n",
    "score_rf   # Random Forest scores for each fold\n",
    "```\n",
    "- Har variable ek list of 5 accuracy values show karega.\n",
    "\n",
    "**Theory:** Scores ke spread se model stability aur variance ka idea milta hai.\n",
    "\n",
    "---\n",
    "## Cell 14–16: `cross_val_score` Shortcut\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(LogisticRegression(), digits.data, digits.target, cv=5)\n",
    "cross_val_score(SVC(),            digits.data, digits.target, cv=5)\n",
    "cross_val_score(RandomForestClassifier(), digits.data, digits.target, cv=5)\n",
    "```\n",
    "- Ek hi function built-in cross-validation run karta hai aur scores return karta hai.\n",
    "\n",
    "**Theory:** `cross_val_score` under the hood StratifiedKFold use karta hai (agar classification task hai) aur convenience ke liye results directly return karta hai.\n",
    "\n",
    "---\n",
    "*Yeh tha K-Fold Cross Validation notebook ka detailed Hinglish explanation + theory. Seedha paste karke apne Jupyter Notebook mein dekho!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7fa075-90bc-4b46-84a4-bfa6e95cb9ea",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc8104-1499-4054-ac3f-54f499577ce7",
   "metadata": {},
   "source": [
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76d97543-e999-48d6-9877-119e194c89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f8d2602-fda2-438d-ab77-3f321f9fb635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guddi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9592592592592593"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce278a41-047c-48d8-b2a8-37f4ff8dd5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07c1e433-a265-4c7f-af17-c20f5c0b16d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796296296296296"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0326b089-308b-4c8f-b153-5754b06298b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# kf=KFold(n_splits=3)\n",
    "# kf.get_n_splits(X_train)\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4329ad1d-23c2-47f6-aae3-05ecd69b01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model,X_train,X_test,y_train,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "595cb21f-abf0-4dab-8d9d-929775652eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guddi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9592592592592593"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(LogisticRegression(),X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0928b106-8d98-4c50-9b8e-6f3cf5ac8e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "score_l=[]\n",
    "score_svm=[]\n",
    "score_rf=[]\n",
    "for train_index, test_index in skf.split(digits.data, digits.target):\n",
    "    X_train, X_test = digits.data[train_index], digits.data[test_index]\n",
    "    y_train, y_test = digits.target[train_index], digits.target[test_index]\n",
    "    score_l.append(get_score(LogisticRegression(max_iter=1000), X_train, X_test, y_train, y_test))\n",
    "    score_svm.append(get_score(SVC(), X_train, X_test, y_train, y_test))\n",
    "    score_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06ceb2ad-aa0b-48ed-8202-e05f835fa0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9222222222222223,\n",
       " 0.8722222222222222,\n",
       " 0.9415041782729805,\n",
       " 0.9415041782729805,\n",
       " 0.8969359331476323]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05f178db-2cc5-4f7b-9eae-3c72ffcd353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9611111111111111,\n",
       " 0.9444444444444444,\n",
       " 0.9832869080779945,\n",
       " 0.9888579387186629,\n",
       " 0.9387186629526463]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2cbb816e-59e3-4696-97b0-c0f6b8240252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9277777777777778,\n",
       " 0.9,\n",
       " 0.9610027855153204,\n",
       " 0.9693593314763231,\n",
       " 0.9275766016713092]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "966d6950-d28d-4de4-b3d5-26cd6f08c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guddi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\guddi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\guddi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\guddi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\guddi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92222222, 0.86944444, 0.94150418, 0.93871866, 0.89693593])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(LogisticRegression(),digits.data,digits.target,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "89fd40a3-6b6a-46aa-8b00-52aa1eddd902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(),digits.data,digits.target,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb6a3592-b397-48b5-ae04-751b2dcdeb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92821369, 0.94991653, 0.93823038])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=60),digits.data,digits.target,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4528f7a-d6e1-4b07-8ad6-34456eb74dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c950f-9dfb-4fd7-b8df-711996615683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
